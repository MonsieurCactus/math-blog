\documentclass[12pt]{article}
%Gumm{\color{blue}i}|065|=)
\usepackage{amsmath, amsfonts, amssymb}
\usepackage[margin=0.5in]{geometry}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amsmath}

\newcommand{\off}[1]{}
\DeclareMathSizes{20}{30}{20}{18}
\usepackage{tikz}


\title{Scratchwork: Riemann-Lebesgue Lemma}
\date{}
\begin{document}

\sffamily

\maketitle

\noindent \textbf{9/14} I've been trying to look at the Prime Number Theorem and how it is proven.  By the time the proof is done, the result looks nothing like a statement about numbers.  Let's see a few:
\begin{itemize}
\item $\pi(x) = \{ \# p < x \}  \sim \frac{x}{\log x} $
\item $\displaystyle \sum_{n < x} \Lambda (n) = x \,\big(1 + o(1)\big)$
\item $\text{lcm} \{ 1, 2, \dots, x\} \asymp e^x $
\end{itemize} 
The first statement makes the primes look ``random".  The second statement suggests the arrangement of primes in $\mathbb{Z}$ approach an almost linear pattern.  We can even interpret the sum as the least-common-multiple of the integers and get an exponential growth pattern. \\ \\
\textbf{Q} How carefully do we have to look in order to prove the prime number theorem?
The original motivation for the van Mangoldt function comes from counting the prime divisors of the factorial function:
$$ p^? \big| 1 \times 2 \times 3 \times \dots \times n = n! $$
We have that near 1850's Chebyshev identifies some useful functions to solving this problem:
\begin{itemize}
\item $\displaystyle  \theta(x) = \sum_{p < x} \log p \asymp x$
\item $\displaystyle  \psi(x) = \sum_{n < x} \Lambda(n) \asymp x$
\item $\displaystyle  \pi(x) = \sum_{p < x}  1 \asymp \frac{x}{\log x}$
\end{itemize}
Between the 1890's and the 1920's stronger statements about the prime number theorem were proven.  The proofs get draconian, and it's unclear that we are reaping the benefits of all our hard work. \\ \\
\textbf{Q} How do dull uninformative estimates combine into more informative approximations?  \\
\textbf{Q} Can the Prime Number Theory be read as a Group Theory problem?  Or a Geometry problem? \\ \\
I can't guarantee you these are new, but who cares?  There are proofs of PNT as recently as 1986 - this problem seems to be uses as a benchmark, against which we can test different techniques.  The authors seem determined to lead you astray.  Here's one of the ``main ideas":
$$ \sum_{p \leq x} \log^2 p + \sum_{pq \leq x} \log p \log q= 2x \log x + O(x)$$
However, the subsequent steps are so difficult that I could never figure out what they mean.  What property of $\mathbb{Z}$ did we just figure out?  To me this is a danger of being too results-oriented.

\newpage 

\noindent Overwhelmingly, the starting point is the unique factorization of integers over $\mathbb{Z}$, which gets locked up into the Euler product:
$$ \zeta(s) =  \sum_{n > 0} \frac{1}{n^s} = \prod_p \left( 1 - \frac{1}{p^s} \right)^{-1}$$
This fact gets checked very carefully.  We know the value of $\zeta(2)$ or $\zeta(-1)$.  Here ``knowing" means that $\zeta(2) \in \pi^2 \mathbb{Q}$ and in fact the fraction is $\frac{1}{6}$.  Over another number field $\mathbb{Q}(\sqrt{d})$ it's an open question what those fractions are.  If the class number is high enough we can't even write down unique factoriztion.  \\ \\
Another part is the Harmonic series is divergent.  This is encoded as the value of the zeta function at $s=1$
$$ \zeta(1) = \sum_{n > 0} \frac{1}{n} = \infty $$
and ``near" $s=1$ the value is still convergent.  E.g. $\zeta(1 + \epsilon)$ and as a holomorphic function near the pole there's an asymptotic expansion:
$$ \zeta(1 + s) = \frac{A}{s-1} + \dots  $$
Then the prime number theorem amounts to showing that $A = 1$ and also showing that:
$$ A = \lim_{x \to \infty} \sum_{n < x} \Lambda(n) \text{ and } \frac{\zeta'(s)}{\zeta(s)} = \sum_{n > 0} \Lambda(n) \, n^{-s}$$
These facts are coming from nowhere and the original questions I have are being lost in the shuffle. \\ \\
This is starting to remind me of a criminal case, where the majority of cases get plea-bargained and very few cases actually go to trial. \\ \\
\textbf{Thm} Let $a: \mathbb{R} \to \mathbb{C}$ be a function.  And let it's Laplace transform be:
$$ \alpha(s) = \int_0^\infty e^{-us} da(u) $$
\begin{itemize}
\item $a$ is non-negative and increasing
\item $r(s) := \alpha(s) - \frac{c}{1-s}$ extends to a continuous function in the close half-plane $s = \sigma + i \tau$ with $\sigma \geq 1$ \\ \\
For example, this is saying that $\alpha(s)$ - the Laplace transform of $a(u)$ - has a pole at $s = 1$.  
\end{itemize}
Then
$$ \int_0^x 1 \, da(u) = c \, e^x + o(e^x) $$
This doesn't even look like a Dirichlet series.  We might like to check that the change of variables $a(u) = A(e^u)$ turns this exponential series into a Dirichlet series and the Laplace transform into a Mellin transform.  \\ \\
\textbf{Thm}
$$ \bigg[ \alpha(s) = \sum_{n=1}^\infty a_n n^{-s} \bigg]\quad\text{and}\quad
\bigg[\alpha(s) - \frac{c}{s-1} \text{ is continuous on }\sigma\geq 1\bigg] \to \bigg[\sum_{n < x} a_n = c \, x + o(x)\bigg] $$ 
None of this is convincing.  The guy is certainly correct.
\vfill
\begin{thebibliography}{}

\item Thomas A. Hulse, M. Ram Murty \textbf{Bertrand's Postulate for Number Fields} \texttt{arXiv:1508.00887}

\item Alina Cojocaru, M. Ram Murty \textbf{An Introduction to Sieve Methods and Their Applications} \\ (London Mathematical Society Student Texts \#66) Cambridge University Press, 2006.

\item Adolf Hildebrand \textbf{The prime number theorem via the large sieve} Mathematika Volume 33, Issue 1 June 1986 , pp. 23-30.

\item Hugh Montgomery, Robert Vaughn. \textbf{Multiplicative Number Theory I: The Classical Theory} (Cambridge Studies in Advanced Mathematics \#97) Cambridge University Press, 2006.

\end{thebibliography}

\noindent \textbf{9/15} I don't remember what I was going to say.  At some point the proof of the Wiener-Ikehara Tauberian theorem uses the Riemann-Lebesgue Lemma.  That one says: \\ \\
\textbf{Thm} If $f$ is (Riemann) integrable on the circle, then $\hat{f}(n) \to 0$ as $|n| \to \infty$. Here's another way of putting it:
$$ \int_0^{2\pi} f(\theta) \, \sin (N\theta) \, d\theta \text{ as } N \to \infty $$
Sounds totally natural.  A function has a Fourier series and the Fourier coefficients should always tend to zero.  No!  \\ \\
\textbf{Thm} Let $f$ be an (Riemann) integrable function on the circle with $f \sim \sum_{n \in \mathbb{Z}} a_n e^{in\theta}$ then we have:
\begin{itemize}
\item $\displaystyle \frac{1}{2\pi}\int_0^{2\pi} | f(\theta) - S_N(f)(\theta)|^2 \, d\theta \to 0 $ as $N \to 0$.  The mean-square convergence of Fourier series.   We could say that the $L^2$ norm $||f - S_N(f)||_{L^2(S^1)} \to 0$.  Or we could call this a ``variance" of some kind.  Pythagoras' theorem $a^2 + b^2 = |a \mathbf{i} + b \mathbf{j}|^2$ is an $L^2$ norm of a 2D space.  So this is a highly geometric statement, even though it may be about noise or something.
\item Parseval's identity
$$ \sum_{n \in \mathbb{Z}} |a_n|^2 = \frac{1}{2\pi}\int_0^{2\pi} |f(\theta)|^2 \, d\theta $$
this is exactly Pythagoras' theore in infinite dimensional space.
\item Bessel Inequality.  $ \sum |a_n|^2 \leq ||f||^2$.  The Hilbert space $\ell^2(\mathbb{Z})$ is somewhat larger than the space of Riemann-integrable functions on the circle.   It's possible to find a sequence of numbers $a_n$ with no Riemann integrable function $f(\theta) = \sum a_n e^{in\theta}$. In order to define $L^2(S^1)$ we really need Lebesgue measure. 
\end{itemize} 
\textbf{9/16} The proof of WT theorem uses Fubini Theorem.  Let $f, g \in L^1(\mathbb{R})$ be two Lebesgue integrable functions then $f*g$ is Lebesgue integrable.  $\widehat{f*g}= \widehat{f}*\widehat{g}$.  These theorems weren't for free when we learned them with Riemann integration, what makes us think we understand them with Lebesgue measure?  Yet
$$ \Big[ f, g \in L^1(\mathbb{R}) \Big] \to \Big[ f * g \in L^1(\mathbb{R}) \Big] $$
Let's put it another way, in the process of using the Fourier transform (or the Mellin Transform) did our function stop being Riemann integrable.  I'm oddly curious how the thing fails to have an integral. \\ \\
Riemann integration was a strong condition it says the partition didn't matter as long as $||\Delta x|| \to 0$, for example that
$$ \frac{1}{N} \sum_{n=1}^N \left(\frac{n}{N}\right)^2 = \frac{1}{3}  + o(1) \text{ but also } \frac{1}{N} \sum_{n=1}^N \{ n \sqrt{2} \}^2 = \frac{1}{3}  + o(1)$$
There should even be some information in the permutation used to put the set $ \{ \{ n \sqrt{2}\} : 0 < n < N \}$ back into order.  As long as the size of the mesh tends to zero any increasing sequence, any partition of $[0,1]$ will do. \\ \\
Let's observe that the map $x \mapsto e^x$ turns the Laplace transform into the Mellin Transform:
$$ \left[ \alpha(s) = \int_0^\infty e^{-us} \, d\Big[\sum_{n < e^x} a_n \Big] =  \sum a_n \, e^{-nx}\right] \to \left[ \alpha(s) = \int_1^\infty v^{-s} \, d\Big[\sum_{n < v} a_n \Big] = \sum a_n \, n^{-s}\right] $$
Because the derivative of a step function is a dirac-delta function.  We have a sum functions like this:
$$ 1_{x > 0} = \left\{ 
\begin{array}{cc} 0 & x < 0 \\ 
1 & x > 0\end{array}\right. \to \frac{d}{dx} (1_{x > 0}) = \delta_0(x)
= \left\{ 
\begin{array}{cc} 0 & x \neq 0 \\ 
?? & x = 0\end{array}\right.$$
Derivative is zero almost everywhere.  We are mostly concerned with the place where the derivative is not zero.  It's undefined. \\ \\
Depending on whether you do Mellin or Fourier transform\dots one is transform of the other. 
$$ \alpha(x) = \sum \Lambda(n) \, e^{-nx} \text{ or } \alpha(s) = \Lambda(n) \, n^{-s} $$
As arithemtic functions we have that $\Lambda * \mu = \log $ this is the M\"{o}bius transform.  We are lost in a sea of transforms:
$$ \beta(x) = \sum_{n > 0}  \log (n)\, e^{-nx} \text{ or } \alpha(s) = \sum_{n > 0}\log(n) \, n^{-s} $$
The rest of the proof seems to fish around for a variant of the Laplace transfor (or of exponential series) that is band-limited.  That occupies a finite amount of frequency space.
\begin{itemize}
\item $\displaystyle \Delta_T(x) = T \left( \frac{\sin \pi T x /2}{\pi T x / 2} \right)^2 $ (Fej\'{e}r Kernel)
\item $\displaystyle J_T(x) = \frac{3T}{4} \left( \frac{\sin \pi T x /2}{\pi T x / 2} \right)^2 $ (Jackson Kernel)
\end{itemize}
Stein - offers us that if $f$ is of moderate decrease, e.g. $|f(x)| \leq \frac{A}{1 + x^2} $ such as $f(x) = e^x 1_{x < 0} $.
$$ \int_{-R}^R \left( 1 - \frac{|\xi|}{R} \right)\hat{f}(\xi) e^{2\pi i \, x \xi} d\xi = (f * \mathcal{F}_R)(x) $$
I'm now completely sure I don't understand this at all.  Here's a sample exercise:
$$ \frac{1}{\pi} \sum_{n \in \mathbb{Z}} \frac{t}{t^2 + n^2} = \sum_{n \in \mathbb{Z}} e^{-2\pi t |n|}$$
This hint is that using Poisson summation $f(x) = t/\pi(x^2 + t^2)$ maps to $\hat{f}(\xi) = e^{- 2\pi t |\xi|}$.  At this point Stein refers us to an Information Theory or Signal Processing textbook. \\ \\
\textbf{Q}: Does the Fejer or Jackson kernel have a Mellin transform cousin?
\vfill
\begin{thebibliography}{}

\item Elias Stein, Rami Shakarchi. \textbf{Analysis I: Fourier Analysis} (Princeton Lectures on Analysis \#1) Princeton Univesity Press, 2003.
\newpage

\noindent Why should we expect Lebesgue integrable functions from prime number theory?  As the number $n \gg 1$ is larger, it's harder and harder to check these numbers are prime.  I can safely compute 7 or 8 digit primes on my laptop.  Is it clear that \textbf{48112959837082048697} is a prime?  Is it that critical that our numbers perfectly multiply? \\ \\ 
Here are some prime numbers {\color{orange!70!black}5099}   {5101}   {\color{orange!70!black}5107}   {5113}   {\color{orange!70!black}5119}   {5147}   {\color{orange!70!black}5153}   {5167}   {\color{orange!70!black}5171}   {5179}.  The Dirichlet series looks awfully sparse:
$$ f(t) = 
5099^{-it} +
5101^{-it} +
5107^{-it} +
5113^{-it} +
5119^{-it} +
5147^{-it} $$
Even moderately sized prime numbers, I'm not sure we've ever studied them very carefully except to get this theoretical result.  \\ \\
\textbf{Q} Find $a, b \in \mathbb{Z}$ such that $5101 = a^2 + b^2$.   Also $5101 = a^2 + 5b^2$.  And $5107 = a^2 + 3b^2$.  The angle $\theta = tan^{-1}(\frac{a}{b}) \notin \pi \mathbb{Q}$ keeps changing and is quite important. 

\end{thebibliography}

\end{document}