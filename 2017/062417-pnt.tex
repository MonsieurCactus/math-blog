\documentclass[12pt]{article}
%Gummi|065|=)
\usepackage{amsmath, amsfonts, amssymb}
\usepackage[margin=0.5in]{geometry}
\usepackage{xcolor}
\usepackage{graphicx}

\newcommand{\off}[1]{}
\DeclareMathSizes{20}{30}{20}{18}

\newcommand{\two }{\sqrt[3]{2}}
\newcommand{\four}{\sqrt[3]{4}}
\newcommand{\red}{\begin{tikz}[scale=0.25]
\draw[fill=red, color=red] (0,0)--(1,0)--(1,1)--(0,1)--cycle;\end{tikz}}
\newcommand{\blue}{\begin{tikz}[scale=0.25]
\draw[fill=blue, color=blue] (0,0)--(1,0)--(1,1)--(0,1)--cycle;\end{tikz}}
\newcommand{\green}{\begin{tikz}[scale=0.25]
\draw[fill=green, color=green] (0,0)--(1,0)--(1,1)--(0,1)--cycle;\end{tikz}}

\newcommand{\sq}[3]{\draw[#3] (#1,#2)--(#1+1,#2)--(#1+1,#2+1)--(#1,#2+1)--cycle;}

\usepackage{tikz}

\newcommand{\susy}{{\bf Q}}
\newcommand{\RV}{{\text{R}_\text{V}}}

\title{Worksheet: Prime Number Theorem}
\author{John D Mangual}
\date{}
\begin{document}

\fontfamily{qag}\selectfont \fontsize{12.5}{15}\selectfont

\maketitle

\noindent Divergent series have always been a very controversial topic and I remain somewhat closeted on the matter.  Hardy's textbook on the subject was published only once he was dead. \\ \\
If I talk about divergent series from the point of view of ``regularization" in Physics, many people I have spoken to consider it mostly solved,  After which, we proceed to open up arXiv and 10 or 20 papers each day clumsily use Ramanujan summation, when maybe they a really meant somethig else.  \\ \\
Therefore, even bringing up the topic is met with open hostility and ridicule.  So I remain on the DL on the  matter. \\ \\
There are two books I really like that get us started:
\begin{itemize}
\item GH Hardy \textbf{Divergent Series}
\item David Vernon Widder \textbf{The Laplace Transform}
\item Don Zagier \textbf{Newman's Short Proof of the Prime Number Theorem}
\item Stephen Hawking \textbf{Zeta function regularization of path integrals in curved spacetime}
\end{itemize}
Number theory could be a source of increasingly ill-behaved series.  There are others, such as pure Combinatorics, or Data Science which is super-trendy.  I have included a short commplex analysis proof (5 pages).\footnote{more complete: \texttt{https://terrytao.wordpress.com/category/teaching/254a-analytic-prime-number-theory/}}  \\ \\
If you noticed my bibliography is rather dated.  The most recent being in the 1970's. \\ \\
My idea is there are even newer ideas that contain and subsume the above.  For reasons that I are very very difficult to explain why I notice and feel this way.\footnote{Wikipedia getes you started, e.g. \texttt{https://en.wikipedia.org/wiki/Zeta\_{}function\_{}regularization}}  This is my blog and so I will waste my time here on such silly considerations. \\ \\
GH Hardy points outs that sine waves at high frequences average to zero.  If you take the square, it's oscillating between $0$ and $1$.  So the average must be $1/2$.  Common sense?
$$   \Bigg[ \epsilon \int_0^{1/\epsilon} \sin^2 mt \, dt =  \frac{1}{2} \Bigg]
\to \Bigg[ \sin^2 mx \to \frac{1}{2} \;\; (C,1) \Bigg]  $$ 
This is called the ``Cesaro average" but if you can't find an answer, and you're looking for the next best thing to do, this is the first thing that comes to mind.  \textbf{Taking the average.}

\newpage

\noindent 
All the prime number theorem proofs rely at some critical point on a way to turn an integral or infinite series, back into information about prime number series.  And they always look completely obvious.  
$$   \Bigg[ \sum a_n = s \Bigg]
\to \Bigg[ \sum a_n x^n  = s \Bigg] \equiv \Bigg[ \sum a_n = s \;\;(A)\Bigg]   $$
This is Abel's Theorem.  Here, please read $\equiv$ as ``the same as".  We are going down a slippery slip since we have written $=$ and $\to$ and $\equiv$ and there could be a few more\dots \\ \\ 
Lot's of Analytic (or Prime) Number Theory as solutions motivated from trigonometric sums, but no longer with any clear interpretation as arrangements of circles or triangles. \\ \\
 These limits will exhibit some truly pathological behavior.\footnote{Lots of these get past in front of our faces without too much question.  And there's not always real cause for anxiety.  In the majority of cases, what we may have proven, is that there really \textbf{isn't} any room for stuff to occur.  You look at it and that's what it is.}  Other's wont.  Perhaps Taylor's theorem forces us into this mess, initially:
$$ f(x + t) = f(x) ) + t f'(x) + \frac{t^2}{2!} f''(x) + \dots = \sum_{k=0}^\infty \frac{t^n}{n!} f^{(n)}(x) $$ 
If we wish, we could streamline the algebraic aspects into a single eq.  It neglects convergence:
$$ f(x+t) = e^{t \, \frac{d}{dx}} f(x) = \Bigg[ \sum_{k=0}^\infty \frac{t^n}{n!} \frac{d^n}{dx^n}\Bigg] f(x)  $$
by the middle of the 20th century, we understand what series like this could mean, but it's been around since the 17th century at or before Newton. At much of its usefulness remains unexplored. \\ \\
These days, when ``data science" is trending, ``regularization" could mean: 
\begin{itemize}
\item de-noising of data / removing garbage
\item making sense (assigning a finite number in a well-behaved way) to an infinite series
\end{itemize}
Maybe the garbage is the thing we wish to inspect; a careful removal of the main term. \\ \\
I saw a type written paper where big-$O$ notation was written as big-$0$ notation:
$$ 0 \to O $$
In many computations, these series have all but disappeared, replaced with sections of schemes and line bundles.  But you still need equations to write these sections down. 
$$ O(x) \leftarrow H_\ast(X) $$
As completely speculative and bonkers as the equation I have written down, sadly it doesn't go far enough.  People like Deligne and Kashiwara have long beaten me to it. \\ \\
A reasonable goal, is to run through Hardy's discussion of the Tauberian theorems of increasing sophistication, and maybe scratch the surface on why a homology theory might be lurking there after all.

\vfill



\begin{thebibliography}{}

\item David Sauzin \textbf{Introduction to 1-summability and resurgence} \texttt{arXiv:1405.0356}

\item J. T. Tate, \textbf{Symbols in Arithmetic}, Actes, Congr\'{e}s Intern. Math., Nice, 1970, Tome 1, Gauthier-Villars(1971), 201-211

\item GH Hardy \textbf{Divergent Series}  Oxford University Press, 1949/1973.

\item Frank Calegari, Akshay Venkatesh.  \textbf{A torsion Jacquet--Langlands correspondence} \texttt{arXiv:1212.3847}

\end{thebibliography}
\vspace{0.5in}

\begin{quotation}
\noindent "The introduction of the digit 0 or the group concept was general nonsense too, and mathematics was more or less stagnating for thousands of years because nobody was around to take such childish steps..." \\ \\
-Alexander Grothendieck
\end{quotation}

\newpage

\noindent I was mostly shooting the breeze when I noticed the Prime Number Theorem was proven in Hardy's divergent series.  The narrative style of Hardy's book is difficut; the theorems are numbered for easy reference, but you are thinking like a computer. 
$$ \Big[ s_n \to s\hspace{0.125in}(A) \Big] \to \Big[ s_n \to s\hspace{0.125in}(C,1) \Big]  $$
Not very helpful.  He unpacks the definitions from the previous chapter:
\begin{itemize}
\item $ \sum a_n r^n \to s  $
\item $ (1-r) \sum s_n r^n \to s  $ with $\displaystyle s_n = \sum^n a_k$
\item $ y \sum s_n e^{-ny} \to s $ or $\frac{1}{x} \sum s_n e^{-n/x} \to s$
\end{itemize} 
The definition on the right is another infinite series $s_n \to s \hspace{0.125in} (C,1)$ means
\begin{itemize}
\item $\frac{1}{x} \sum_{n \leq x} s_n \to s $
\end{itemize}
The implication looks like:
$$ \Bigg[ (1-r) \sum s_n r^n \to s \Bigg] \to \Bigg[ \frac{1}{x} \sum_{n \leq x} s_n \to s \Bigg]  $$
or possibly, keeping the same goal and substituting $r = e^{n/x}$: 
$$ \Bigg[ \frac{1}{x} \sum_{n=0}^\infty s_n e^{n/x} \to s \Bigg] \;\;\to \;\;\Bigg[ \frac{1}{x} \sum_{n \leq x} s_n \to s \Bigg]  $$
and think about it.  $x \gg 1$ is a big number, therefore $\frac{1}{x} \approx 0$. \\ \\ Could we prove the Prime Number Theorem this way?  Hardy did.  Or Littlewood.  One of them.  Even though the van Mangoldt function is not a partial sum,\footnote{we'd have $a_n = \Lambda(n) - \Lambda(n-1) = \log p - \log q$ for random prime numbers $p,q$. } set $s_n = \Lambda(n) $.
$$ \Bigg[ (1-r) \sum_{n=1}^\infty \Lambda(n) \; r^n \to 1 \Bigg] \to \Bigg[ \frac{1}{x} \sum_{n \leq x} \Lambda(n) \to 1 \Bigg]  $$
and this is what he showed.  This is called \textbf{Karamata theorem} or \textbf{Hardy-Littlewood Tauberian Theorem} depending on which argument you use.  Except, $\Lambda(n) \neq O(1)$.  That'd be Hardy Theorem 92.
$$ \Bigg[ \frac{1}{x} \sum_{n=1}^\infty \Lambda(n) \; e^{n/x} \to 1 \Bigg] \to \Bigg[ \frac{1}{x} \sum_{n \leq x} \Lambda(n) \to 1 \Bigg]  $$
Hardy has Theorem 93, with $\Lambda(n) \geq 0$.  I forget how he gets around this.  Something easy.  Except, somehow we'd have to establish: 
$$ \frac{1}{x} \sum_{n=1}^\infty \Lambda(n) \; e^{n/x} \to 1 $$
It is true.  Hardy did it.  I don't know how to do it still.

\newpage
We know this can't be right, because there's a piece of information I haven't included yet. 
$$ \zeta( 1 + it) \neq 0 $$
and then it took me a long time to think, where did the \textbf{non-vanishing} of a number play such a cricial r\^{o}le.  It's just that we need to avoid a divide by zero.
$$ \bigg[ d\log f(x) = \frac{f'(x)}{f(x)} \bigg] \to \bigg[ d \log \zeta(x) = \frac{\zeta'(x)}{\zeta(x)}\bigg]  $$
If I write it with $f$ it looks like a calculus textbook.  Instead I write it with $\zeta$ it looks exotic.  We're sure $\zeta(z) \neq 0$ for $\mathrm{Re}(z) > \frac{1}{2}$ so we haven't used any of the information really availble to us.  However  $\zeta(1 + it) \neq 0$ is the bare minimum for ``proof". \\ \\
Just as a reminder here's how it is proved in the divergent series book, using a different summation method:
$$ \Bigg[ x\sum_{n=1}^\infty \Lambda(n) \left[ \frac{d}{d(nx)} \frac{nx e^{-nx}}{e^{-nx} - 1} \right] = 1 \Bigg] \to \left[ x \sum_{n=1}^{\frac{1}{x}} \Lambda(n) = 1 \right] $$
We know to prove the left side, very easily but the implication $\to$ is next to impossible. \\ \\
None of these summation methods, look like ``regularization" or ``resummation", yet.  Just reminder to self.

\newpage

\noindent \textbf{7/01} How do we begin the somewhat terrifying descent towards the Wiener-Ikehara Tauberian theorem?  I suspect number theorists are correct that results of these kind are old-fashioned and too specialized. \\ \\
So are we going to back to mindlessly manipulating sums? \\ \\
Tauberian Theorems offer us a connection between number theory and regularization.  The Complex Analysis proof should as well.  Even that short 6-page proof by Newman (as discussed by Don Zagier).   \\ \\
If I knew Real Analysis / Functional Analysis better maybe I could devise a broader .  Or at least, I could articulate better what makes these things so difficult. And finally, maybe it's time to expand our scope beyond the Prime Number Theorem? \\ \\
My best guess is that Dirichlet series, while they can be politely written down as sequences of numbers, they will have very chaotic ``analytic properties" as functions of $\mathbb{C}$.  Therefore I was going to suggest we use {\color{red!70!yellow!80!green} splines}. \\ \\
In my opinion why not stop there?  We can turn them into functions of $\mathbb{H}$ or $\mathrm{PSL}_2(\mathbb{R})$?  These maps will be functorial.  We could lift functions, we could lift maps we could lift everything, I think. \\ \\
If $\zeta(\frac{1}{2} + it)$ is so badly chaotic, maybe the best we can do is take averages?  This is starting to sound like \textbf{ergodic theory}.  GH Hardy's treatment does not use ergodic theory, which was stll being developed.  By now the book is somewhat dated, it doesn't play by the rules but it is very forward-thinking.

\vfill



\begin{thebibliography}{}

\item David Sauzin \textbf{Introduction to 1-summability and resurgence} \texttt{arXiv:1405.0356}

\item J. T. Tate, \textbf{Symbols in Arithmetic}, Actes, Congr\'{e}s Intern. Math., Nice, 1970, Tome 1, Gauthier-Villars(1971), 201-211

\item GH Hardy \textbf{Divergent Series}  Oxford University Press, 1949/1973.

\item Theodore Rivlin \textbf{An Introduction to the Approximation of Functions}

\end{thebibliography}
\end{document}